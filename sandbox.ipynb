{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6a4fa4f-b995-4bea-8698-074ec773cb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "import seaborn as sns\n",
    "from Bio import SeqIO, Seq\n",
    "\n",
    "import glob, os, yaml, subprocess, itertools, sparse, vcf\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "import sklearn.metrics\n",
    "from sklearn.decomposition import PCA\n",
    "import timeit\n",
    "import scipy.stats as st\n",
    "\n",
    "who_variants = pd.read_csv(\"/n/data1/hms/dbmi/farhat/Sanjana/MIC_data/WHO_resistance_variants_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "bccade69-bbd6-4fc4-9ff7-69c0434597d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiers for this model: ['1']\n",
      "9751 samples with phenotypes for Rifampicin\n",
      "Working on dataframe 1/1\n",
      "/n/data1/hms/dbmi/farhat/ye12/who/full_genotypes/drug_name=Rifampicin/tier=1/run-1660066839545-part-r-00014\n"
     ]
    }
   ],
   "source": [
    "kwargs = yaml.safe_load(open(\"config_rif.yaml\"))\n",
    "\n",
    "tiers_lst = kwargs[\"tiers_lst\"]\n",
    "drug = kwargs[\"drug\"]\n",
    "out_dir = kwargs[\"out_dir\"]\n",
    "model_prefix = kwargs[\"model_prefix\"]\n",
    "missing_thresh = kwargs[\"missing_thresh\"]\n",
    "het_mode = kwargs[\"het_mode\"]\n",
    "af_thresh = kwargs[\"AF_thresh\"]\n",
    "\n",
    "print(\"Tiers for this model:\", tiers_lst)\n",
    "\n",
    "if not os.path.isdir(os.path.join(out_dir, drug)):\n",
    "    print(f\"Creating output directory {os.path.join(out_dir, drug)}\")\n",
    "    os.mkdir(os.path.join(out_dir, drug))\n",
    "    \n",
    "if not os.path.isdir(os.path.join(out_dir, drug, model_prefix)):\n",
    "    print(f\"Creating output directory {os.path.join(out_dir, drug, model_prefix)}\")\n",
    "    os.mkdir(os.path.join(out_dir, drug, model_prefix))\n",
    "\n",
    "genos_dir = '/n/data1/hms/dbmi/farhat/ye12/who/full_genotypes'\n",
    "phenos_dir = '/n/data1/hms/dbmi/farhat/ye12/who/phenotypes'\n",
    "phenos_dir = os.path.join(phenos_dir, f\"drug_name={drug}\")\n",
    "\n",
    "dfs_list_phenos = []\n",
    "\n",
    "for fName in os.listdir(phenos_dir):\n",
    "    dfs_list_phenos.append(pd.read_csv(os.path.join(phenos_dir, fName)))\n",
    "\n",
    "df_phenos = pd.concat(dfs_list_phenos)\n",
    "\n",
    "# check that there are no duplicated phenotypes\n",
    "assert len(df_phenos) == len(df_phenos.sample_id.unique())\n",
    "\n",
    "# check that there is resistance data for all samples\n",
    "assert sum(pd.isnull(df_phenos.phenotype)) == 0\n",
    "    \n",
    "print(f\"{len(df_phenos)} samples with phenotypes for {drug}\")\n",
    "\n",
    "# first get all the genotype files associated with the drug\n",
    "geno_files = []\n",
    "\n",
    "for subdir in os.listdir(os.path.join(genos_dir, f\"drug_name={drug}\")):\n",
    "    \n",
    "    # subdirectory (tiers)\n",
    "    full_subdir = os.path.join(genos_dir, f\"drug_name={drug}\", subdir)\n",
    "\n",
    "    # the last character is the tier number\n",
    "    if subdir[-1] in tiers_lst:\n",
    "        \n",
    "        for fName in os.listdir(full_subdir):\n",
    "            \n",
    "            # some hidden files (i.e. Git files) are present, so ignore them\n",
    "            if fName[0] != \".\":\n",
    "                geno_files.append(os.path.join(full_subdir, fName))\n",
    "          \n",
    "        \n",
    "dfs_lst = []\n",
    "for i, fName in enumerate(geno_files):\n",
    "        \n",
    "    print(f\"Working on dataframe {i+1}/{len(geno_files)}\")\n",
    "    print(fName)\n",
    "\n",
    "    # read in the dataframe\n",
    "    df = pd.read_csv(fName)\n",
    "\n",
    "    df_avail_isolates = df.loc[df.sample_id.isin(df_phenos.sample_id)]\n",
    "    \n",
    "    # keep all variants\n",
    "    #dfs_lst.append(df_avail_isolates)\n",
    "\n",
    "    # keep only 1) noncoding variants and 2) non-synonymous variants in coding regions. \n",
    "    # P = coding variants, C = synonymous or upstream variants, and N = non-coding variants on rrs/rrl\n",
    "    dfs_lst.append(df_avail_isolates.loc[((df_avail_isolates.category.astype(str).str[0] == 'c') & (df_avail_isolates.category.str.contains('-'))) | \n",
    "                                         (df_avail_isolates.category.astype(str).str[0].isin(['n', 'p']))])\n",
    "        \n",
    "df_model = pd.concat(dfs_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "c8a5e2fb-9bbe-456b-a33f-67c808e46815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15259170, 5)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "0ef60921-0b94-4ef4-b94d-4fb38c262847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8150340, 5)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "cec3cb93-798d-4e48-b976-82546eefed3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Seq('G'), Seq('G'))"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Seq.Seq(\"GGC\").translate(), Seq.Seq(\"GGT\").translate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "c22b4c5f-8742-48ea-a63c-ac06362e6d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Seq('R'), Seq('R'))"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Seq.Seq(\"CGT\").translate(), Seq.Seq(\"CGC\").translate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8342710d-f7cd-4083-b8e4-f580d6b87eb8",
   "metadata": {},
   "source": [
    "# Numbers of features and isolates dropped at different thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21eebf8f-2ced-4290-81ee-303a46d35bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6852, 3355)\n"
     ]
    }
   ],
   "source": [
    "prefilt = pd.read_pickle(\"/n/data1/hms/dbmi/farhat/ye12/who/analysis/Amikacin/tiers=1_2_encode_HET_as_WT_prefilt.pkl\")\n",
    "#filt = pd.read_pickle(\"/n/data1/hms/dbmi/farhat/ye12/who/analysis/Amikacin/tiers=1_2_encode_HET_as_WT.pkl\")\n",
    "print(prefilt.shape)\n",
    "#print(filt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9274721-9adb-45a3-aa2d-9d3cb4f00023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_threshold_summaries(prefilt, missing_thresh=None):\n",
    "    \n",
    "    # drop all isolates with more than 1 missing feature\n",
    "    if missing_thresh is None:\n",
    "        filt_isolates = prefilt.dropna(axis=0, thresh=prefilt.shape[1]-1)\n",
    "    else:\n",
    "        filt_isolates = prefilt.dropna(axis=0, thresh=(1-missing_thresh)*prefilt.shape[1])\n",
    "        \n",
    "    # remove all features with ANYTHING missing\n",
    "    filt_feat = filt_isolates.dropna(axis=1)\n",
    "    print(filt_feat.shape)\n",
    "    print(f\"Dropped {prefilt.shape[0] - filt_isolates.shape[0]} out of {prefilt.shape[0]} isolates and {prefilt.shape[1] - filt_feat.shape[1]} out of {prefilt.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b75dbec-8ea8-421c-9a04-daf7faca07e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6585, 3355)\n",
      "Dropped 267 out of 6852 isolates and 0 out of 3355 features\n"
     ]
    }
   ],
   "source": [
    "# 1 isolate threshold\n",
    "print_threshold_summaries(prefilt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "cb19a88f-b0e5-4300-8c64-34507ae209e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6585, 3355)\n",
      "Dropped 267 out of 6852 isolates and 0 out of 3355 features\n"
     ]
    }
   ],
   "source": [
    "# 1% isolate threshold\n",
    "print_threshold_summaries(prefilt, missing_thresh=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "6f00ffdb-4b2a-4764-aacc-cc2a6bb1d2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6590, 3267)\n",
      "Dropped 262 out of 6852 isolates and 88 out of 3355 features\n"
     ]
    }
   ],
   "source": [
    "# 5% isolate threshold\n",
    "print_threshold_summaries(prefilt, missing_thresh=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "483dd3f9-9755-4301-bfe8-eab8e777d3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6626, 2680)\n",
      "Dropped 226 out of 6852 isolates and 675 out of 3355 features\n"
     ]
    }
   ],
   "source": [
    "# 10% isolate threshold\n",
    "print_threshold_summaries(prefilt, missing_thresh=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b564ed2f-7727-4b68-800d-0002745868d3",
   "metadata": {},
   "source": [
    "# Unused functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfde331f-3914-4adb-951b-150afe963506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_null_regression(var_idx, num_bootstrap=100):\n",
    "        \n",
    "    # make variant of interest all 0 so that its coefficient will be 0\n",
    "    df = model_inputs.copy()\n",
    "    if \"sample_id\" in df.columns:\n",
    "        df = df.set_index(\"sample_id\")\n",
    "    df.iloc[:, var_idx] = 0\n",
    "    \n",
    "    # concatenate the eigenvectors to the matrix\n",
    "    X = np.concatenate([df.values, eigenvec_df.values], axis=1)\n",
    "\n",
    "    # scale inputs\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    assert len(y) == X.shape[0]\n",
    "    \n",
    "    coef_lst = []\n",
    "    for _ in range(num_bootstrap):\n",
    "        null_model = LogisticRegressionCV(Cs=1/np.logspace(-4, 4, 9), \n",
    "                                 cv=5,\n",
    "                                 penalty='l2', \n",
    "                                 max_iter=10000, \n",
    "                                 multi_class='ovr',\n",
    "                                 scoring='neg_log_loss'\n",
    "                                )\n",
    "\n",
    "        null_model.fit(X, y)\n",
    "        coef_lst.append(np.squeeze(null_model.coef_)[var_idx])\n",
    "    return coef_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9a3d10-7c61-42de-9816-835f6ad96a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pvalues_add_ci(baseline_df, bs_df, col, ci=95):\n",
    "    \n",
    "    alpha = (100-ci)/100\n",
    "    baseline_df[col] = baseline_df[col].astype(str)\n",
    "    pvals = []\n",
    "    for i, pos in enumerate(baseline_df[col].values):\n",
    "        \n",
    "        # get the percentile of 0\n",
    "        ecdf = ECDF(bs_df[pos].values)\n",
    "        zero_percentile = ecdf(0)\n",
    "        \n",
    "        # if the percentile is greater than 0.5, then the hypothesis test is for probability of lying in the upper tail (i.e. > 97.5 for a 95% CI)\n",
    "        # if the percentile i less than 0.5, then the hypothesis test is for probability of lying in the lower tail (i.e. < 2.5 for a 95% CI)\n",
    "        if zero_percentile > 1 or zero_percentile < 0:\n",
    "            print(pos)\n",
    "        \n",
    "        if zero_percentile < 0.5:\n",
    "            pvals.append(2 * zero_percentile)\n",
    "        else:\n",
    "            pvals.append(2 * (1 - zero_percentile))\n",
    "            \n",
    "        # add confidence intervals\n",
    "        diff = (100-ci)/2\n",
    "        lower, upper = np.percentile(bs_df[pos].values, q=(diff, 100-diff))\n",
    "        baseline_df.loc[i, \"Lower_CI\"] = lower\n",
    "        baseline_df.loc[i, \"Upper_CI\"] = upper\n",
    "        \n",
    "    pvals = np.array(pvals)\n",
    "    return pvals, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d449a1-17bb-4207-bbb7-36eabe416164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def volcano_plot(baseline_df, bs_df, col, pvals, ci=95, exclude_lst=[], label_thresh=0, title_suffix=\"\", saveFig=None):\n",
    "        \n",
    "    # replace 0s so that log can be taken for plotting\n",
    "    if len(np.unique(pvals)) > 1:\n",
    "        min_non_zero = np.sort(np.unique(pvals))[1]\n",
    "    else:\n",
    "        min_non_zero = 1e-3\n",
    "    pvals[pvals == 0] = min_non_zero\n",
    "        \n",
    "   baseline_df[\"neg_log_pval\"] = -np.log(pvals)\n",
    "   baseline_df[\"pval_significant\"] = (baseline_df[\"pval\"] < alpha).astype(int)\n",
    "    \n",
    "    # verify input order\n",
    "    assert len(bs_df.columns) == len(set(bs_df.columns).intersection(baseline_df[col].values))\n",
    "    \n",
    "    # only plot features with nonzero coefficients\n",
    "    bs_df_positive = baseline_df.query(\"coef > 0\")\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    sns.scatterplot(data=baseline_df.loc[~baseline_df[col].isin(exclude_lst)], x=\"coef\", y=\"neg_log_pval\", \n",
    "                    alpha=0.75,\n",
    "                    hue=\"pval_significant\", \n",
    "                    s=30,\n",
    "                    palette={1:\"darkred\", 0:\"lightgray\"},\n",
    "                    ax=ax)\n",
    "\n",
    "    ax.legend().set_visible(False)\n",
    "    #plt.xscale(\"log\")\n",
    "    plt.title(\"Ridge Regression Coefficients and Bootstrapped\\np-values\" + title_suffix + f\", α = {alpha}\")\n",
    "    sns.despine()\n",
    "    \n",
    "    if saveFig is not None:\n",
    "        plt.savefig(saveFig, dpi=300, bbox_inches=\"tight\")\n",
    "    else:\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
