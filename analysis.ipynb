{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4647438-032f-45bc-acab-e16b6955dbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 125\n",
    "import seaborn as sns\n",
    "from Bio import SeqIO, Seq\n",
    "import scipy.stats as st\n",
    "import glob, os, yaml, subprocess, itertools, sparse, vcf\n",
    "\n",
    "who_variants = pd.read_csv(\"/n/data1/hms/dbmi/farhat/Sanjana/MIC_data/WHO_resistance_variants_all.csv\")\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9daf0d89-bc7e-4576-b62e-bcc3282d7f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models_population_structure_correction(pop_corr, no_pop_corr, plot=False, alpha=0.05, diff_thresh=0):\n",
    "    '''\n",
    "    Comparison to determine if population structure determination is necessary. Things to compare:\n",
    "    \n",
    "    1. Do all the same variants have non-zero coefficients (the returned dataframes are only non-zero coefficients)?\n",
    "    2. Compute Pearson correlation between coefficients.\n",
    "    3. Do features have p-values that are on the same side of the threshold (0.05 or 0.01)?\n",
    "    '''\n",
    "    \n",
    "    # merge outer to include anything (in case some features have 0 or non-zero coefficients, depending on whether PCs are included)\n",
    "    plot_df = pop_corr[[\"orig_variant\", \"coef\", \"pval\", \"BH_pval\", \"coef_LB\", \"coef_UB\"]].merge(no_pop_corr[[\"orig_variant\", \"coef\", \"pval\", \"BH_pval\", \"coef_LB\", \"coef_UB\"]], how=\"outer\", on=\"orig_variant\")    \n",
    "    \n",
    "    # then drop the principal components\n",
    "    plot_df = plot_df.loc[~plot_df[\"orig_variant\"].str.contains(\"PC\")]\n",
    "    \n",
    "    # plot_df_missing = plot_df.loc[(pd.isnull(plot_df[\"coef_x\"])) | (pd.isnull(plot_df[\"coef_y\"]))]\n",
    "    # print(f\"{len(plot_df_missing)} coefficients are zero in one model and non-zero in the other\")\n",
    "    # plot_df_nominal_sig = plot_df.query(\"pval_x < @alpha & pval_y < @alpha\")\n",
    "    # print(\"   \", len(plot_df_nominal_sig.query(\"(coef_x < 0 & coef_y > 0) | (coef_x > 0 & coef_y < 0)\")), \"nominally significant features have conflicting coefficients\")\n",
    "    \n",
    "    plot_df_sig = plot_df.query(\"BH_pval_x < @alpha & BH_pval_y < @alpha\")\n",
    "    print(\"   \", len(plot_df_sig.query(\"(coef_x < 0 & coef_y > 0) | (coef_x > 0 & coef_y < 0)\")), \"significant features have conflicting coefficients\")    \n",
    "    \n",
    "    # NaNs are 0 coefficients, fill them in for plotting and correlation computations\n",
    "    plot_df[[\"coef_x\", \"coef_y\"]] = plot_df[[\"coef_x\", \"coef_y\"]].fillna(0)\n",
    "    \n",
    "    # coefficient without population structure correction - coefficient with correction\n",
    "    plot_df[\"diff\"] = plot_df[\"coef_y\"] - plot_df[\"coef_x\"]\n",
    "    plot_df[\"norm_diff\"] = plot_df[\"diff\"] / plot_df[\"coef_x\"]\n",
    "\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(9, 3))\n",
    "        sns.scatterplot(data=plot_df, x=\"coef_x\", y=\"coef_y\", ax=ax[0], alpha=0.5)\n",
    "        ax[0].set_xlabel(\"Coef, Population Structure Correction\")\n",
    "        ax[0].set_ylabel(\"Coef, No Correction\")\n",
    "        ax[0].set_title(np.round(st.pearsonr(plot_df['coef_x'], plot_df['coef_y'])[0], 4), \"Pearson R\")\n",
    "\n",
    "        sns.scatterplot(data=plot_df, x=\"coef_x\", y=\"norm_diff\", ax=ax[1], alpha=0.5)\n",
    "        ax[1].set_xlabel(\"Coef, Population Structure Correction\")\n",
    "        ax[1].set_ylabel(\"\")\n",
    "        ax[1].set_title(\"Norm. Difference in Coefs.\")\n",
    "\n",
    "        sns.despine()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"   \", np.round(st.pearsonr(plot_df['coef_x'], plot_df['coef_y'])[0], 4), \"Pearson R\")\n",
    "    \n",
    "    # get features whose coefficients differ by more than some threshold (0 to 100) for percent difference\n",
    "    # (difference between coefficients without and with correction is greater than the coefficient with population structure correction\n",
    "    #large_diff = plot_df.query(\"percent_diff >= @diff_thresh | percent_diff <= -@diff_thresh\")\n",
    "    \n",
    "    # get the number of features with confidence intervals that lie on different sides of 0\n",
    "    print('   ', len(plot_df.query(\"coef_LB_x > 0 & coef_UB_x > 0 & coef_LB_y < 0 & coef_UB_y < 0\")), 'features have confidence intervals on different sides of 0')\n",
    "    #print(f'{len(large_diff.query(\"coef_LB_x > 0 & coef_UB_x > 0 & coef_LB_y < 0 & coef_UB_y < 0\"))} features with very different coefficients have confidence intervals on different sides of 0')\n",
    "    \n",
    "    # TO-DO: COMPARISON OF CONFIDENCE INTERVALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37b0349c-af23-4a72-b246-9b637512536b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 drugs with phenotypes and genotypes\n"
     ]
    }
   ],
   "source": [
    "genos_dir = '/n/data1/hms/dbmi/farhat/ye12/who/full_genotypes'\n",
    "phenos_dir = '/n/data1/hms/dbmi/farhat/ye12/who/phenotypes'\n",
    "analysis_dir = '/n/data1/hms/dbmi/farhat/ye12/who/analysis'\n",
    "\n",
    "pheno_drugs = os.listdir(phenos_dir)\n",
    "geno_drugs = os.listdir(genos_dir)\n",
    "\n",
    "drugs_for_analysis = list(set(geno_drugs).intersection(set(pheno_drugs)))\n",
    "print(len(drugs_for_analysis), \"drugs with phenotypes and genotypes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34fa06c4-f8d0-4f15-893b-12db753c7cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kanamycin\n",
      "    3 principal components have non-zero coefficients\n",
      "    0 significant features have conflicting coefficients\n",
      "    0.9992 Pearson R\n",
      "    0 features have confidence intervals on different sides of 0\n",
      "\n",
      "\n",
      "Rifampicin\n",
      "    2 principal components have non-zero coefficients\n",
      "    0 significant features have conflicting coefficients\n",
      "    0.9995 Pearson R\n",
      "    0 features have confidence intervals on different sides of 0\n",
      "\n",
      "\n",
      "Ethambutol\n",
      "    2 principal components have non-zero coefficients\n",
      "    0 significant features have conflicting coefficients\n",
      "    0.9921 Pearson R\n",
      "    0 features have confidence intervals on different sides of 0\n",
      "\n",
      "\n",
      "Amikacin\n",
      "    2 principal components have non-zero coefficients\n",
      "    0 significant features have conflicting coefficients\n",
      "    0.9998 Pearson R\n",
      "    0 features have confidence intervals on different sides of 0\n",
      "\n",
      "\n",
      "Delamanid\n",
      "    5 principal components have non-zero coefficients\n",
      "    0 significant features have conflicting coefficients\n",
      "    0.9787 Pearson R\n",
      "    0 features have confidence intervals on different sides of 0\n",
      "\n",
      "\n",
      "Moxifloxacin\n",
      "    1 principal components have non-zero coefficients\n",
      "    0 significant features have conflicting coefficients\n",
      "    0.9985 Pearson R\n",
      "    0 features have confidence intervals on different sides of 0\n",
      "\n",
      "\n",
      "Levofloxacin\n",
      "    3 principal components have non-zero coefficients\n",
      "    0 significant features have conflicting coefficients\n",
      "    0.9998 Pearson R\n",
      "    0 features have confidence intervals on different sides of 0\n",
      "\n",
      "\n",
      "Streptomycin\n",
      "    3 principal components have non-zero coefficients\n",
      "    0 significant features have conflicting coefficients\n",
      "    0.9987 Pearson R\n",
      "    0 features have confidence intervals on different sides of 0\n",
      "\n",
      "\n",
      "Capreomycin\n",
      "    2 principal components have non-zero coefficients\n",
      "    0 significant features have conflicting coefficients\n",
      "    0.9998 Pearson R\n",
      "    0 features have confidence intervals on different sides of 0\n",
      "\n",
      "\n",
      "Isoniazid\n",
      "    3 principal components have non-zero coefficients\n",
      "    1 significant features have conflicting coefficients\n",
      "    0.9938 Pearson R\n",
      "    0 features have confidence intervals on different sides of 0\n",
      "\n",
      "\n",
      "Clofazimine\n",
      "    2 principal components have non-zero coefficients\n",
      "    0 significant features have conflicting coefficients\n",
      "    0.9945 Pearson R\n",
      "    0 features have confidence intervals on different sides of 0\n",
      "\n",
      "\n",
      "Ethionamide\n",
      "    1 principal components have non-zero coefficients\n",
      "    0 significant features have conflicting coefficients\n",
      "    0.9989 Pearson R\n",
      "    0 features have confidence intervals on different sides of 0\n",
      "\n",
      "\n",
      "Pyrazinamide\n",
      "    3 principal components have non-zero coefficients\n",
      "    0 significant features have conflicting coefficients\n",
      "    0.9952 Pearson R\n",
      "    0 features have confidence intervals on different sides of 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for drug in drugs_for_analysis:\n",
    "    \n",
    "    drug = drug.split(\"=\")[1]\n",
    "    out_dir = os.path.join(analysis_dir, drug, \"tiers=1/phenos=WHO\")\n",
    "    corr_prefix = \"dropAF_noSyn\"\n",
    "    no_corr_prefix = \"dropAF_noSyn_noPopCorr\"\n",
    "    \n",
    "    if os.path.isfile(os.path.join(out_dir, corr_prefix, \"model_analysis.pkl\")) and os.path.isfile(os.path.join(out_dir, no_corr_prefix, \"model_analysis.pkl\")):\n",
    "        \n",
    "        print(drug)\n",
    "        pop_corr = pd.read_pickle(os.path.join(out_dir, corr_prefix, \"model_analysis.pkl\"))\n",
    "        no_pop_corr = pd.read_pickle(os.path.join(out_dir, no_corr_prefix, \"model_analysis.pkl\"))\n",
    "\n",
    "        # number of principal components with positive coefficients (OR > 1)\n",
    "        print(\"   \", len(pop_corr.query(\"coef > 0\").loc[pop_corr.query(\"coef > 0\").orig_variant.str.contains('PC')]), \"principal components have non-zero coefficients\")\n",
    "        \n",
    "        # variants in moxi_res that are not in the results without population structure correction\n",
    "        overlap_variants = set(pop_corr.loc[~pop_corr[\"orig_variant\"].str.contains(\"PC\")][\"orig_variant\"]).intersection(set(no_pop_corr[\"orig_variant\"]))\n",
    "        if len(overlap_variants) == len(pop_corr.loc[~pop_corr[\"orig_variant\"].str.contains(\"PC\")]) == len(no_pop_corr):\n",
    "            compare_models_population_structure_correction(pop_corr, no_pop_corr, plot=False, alpha=0.05, diff_thresh=0)\n",
    "        else:\n",
    "            print(\"    Differing non-zero coefficients\")        \n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e590a4f-0b52-4338-844c-3522cb5660c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#who_variants.loc[(who_variants.drug == 'PZA') & (who_variants.confidence.str.contains(\"|\".join([\"1\"])))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7726ce8-605b-4e29-aa53-ecdd1f260e37",
   "metadata": {},
   "source": [
    "# 1 variant in INH has positive or negative coefficients in the 2 different models\n",
    "\n",
    "## It's a category 5 mutation, and the confidence intervals are significant\n",
    "\n",
    "## The other 2 variants do not have significant p-values, and the confidence intervals are not fully above or below 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7205f478-ec9e-4d70-a175-c2cf982bde88",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug = \"Isoniazid\"\n",
    "out_dir = os.path.join(analysis_dir, drug, \"tiers=1/phenos=WHO\")\n",
    "corr_prefix = \"dropAF_noSyn\"\n",
    "no_corr_prefix = \"dropAF_noSyn_noPopCorr\"\n",
    "\n",
    "pop_corr = pd.read_pickle(os.path.join(out_dir, corr_prefix, \"model_analysis.pkl\"))\n",
    "no_pop_corr = pd.read_pickle(os.path.join(out_dir, no_corr_prefix, \"model_analysis.pkl\"))\n",
    "\n",
    "plot_df = pop_corr[[\"orig_variant\", \"coef\", \"pval\", \"BH_pval\", \"coef_LB\", \"coef_UB\", \"confidence_WHO_2021\"]].merge(no_pop_corr[[\"orig_variant\", \"coef\", \"pval\", \"BH_pval\", \"coef_LB\", \"coef_UB\", \"confidence_WHO_2021\"]], how=\"outer\", on=\"orig_variant\")    \n",
    "    \n",
    "# then drop the principal components\n",
    "plot_df = plot_df.loc[~plot_df[\"orig_variant\"].str.contains(\"PC\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e613588f-c396-44cf-82b4-367c6ffe1f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig_variant</th>\n",
       "      <th>coef_x</th>\n",
       "      <th>pval_x</th>\n",
       "      <th>BH_pval_x</th>\n",
       "      <th>coef_LB_x</th>\n",
       "      <th>coef_UB_x</th>\n",
       "      <th>confidence_WHO_2021_x</th>\n",
       "      <th>coef_y</th>\n",
       "      <th>pval_y</th>\n",
       "      <th>BH_pval_y</th>\n",
       "      <th>coef_LB_y</th>\n",
       "      <th>coef_UB_y</th>\n",
       "      <th>confidence_WHO_2021_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>katG_p.Asn529Thr</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.4412</td>\n",
       "      <td>0.6160</td>\n",
       "      <td>-0.0171</td>\n",
       "      <td>0.0216</td>\n",
       "      <td>3) Uncertain significance</td>\n",
       "      <td>-0.0014</td>\n",
       "      <td>0.4312</td>\n",
       "      <td>0.6037</td>\n",
       "      <td>-0.0145</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>3) Uncertain significance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>katG_c.-28G&gt;T</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.4942</td>\n",
       "      <td>0.6829</td>\n",
       "      <td>-0.0175</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>3) Uncertain significance</td>\n",
       "      <td>-0.0008</td>\n",
       "      <td>0.4685</td>\n",
       "      <td>0.6502</td>\n",
       "      <td>-0.0185</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>3) Uncertain significance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>katG_p.Arg463Leu</td>\n",
       "      <td>-0.1853</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>-0.2719</td>\n",
       "      <td>-0.0975</td>\n",
       "      <td>5) Not assoc w R</td>\n",
       "      <td>0.1827</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1364</td>\n",
       "      <td>0.2290</td>\n",
       "      <td>5) Not assoc w R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          orig_variant  coef_x  pval_x  BH_pval_x  coef_LB_x  coef_UB_x  \\\n",
       "731   katG_p.Asn529Thr  0.0012  0.4412     0.6160    -0.0171     0.0216   \n",
       "758      katG_c.-28G>T  0.0001  0.4942     0.6829    -0.0175     0.0176   \n",
       "1317  katG_p.Arg463Leu -0.1853  0.0000     0.0005    -0.2719    -0.0975   \n",
       "\n",
       "          confidence_WHO_2021_x  coef_y  pval_y  BH_pval_y  coef_LB_y  \\\n",
       "731   3) Uncertain significance -0.0014  0.4312     0.6037    -0.0145   \n",
       "758   3) Uncertain significance -0.0008  0.4685     0.6502    -0.0185   \n",
       "1317           5) Not assoc w R  0.1827  0.0000     0.0000     0.1364   \n",
       "\n",
       "      coef_UB_y      confidence_WHO_2021_y  \n",
       "731      0.0192  3) Uncertain significance  \n",
       "758      0.0162  3) Uncertain significance  \n",
       "1317     0.2290           5) Not assoc w R  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_df.query(\"(coef_x < 0 & coef_y > 0) | (coef_x > 0 & coef_y < 0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4138721d-e0ea-41a7-b063-3682c05562df",
   "metadata": {},
   "source": [
    "# TO-DO: Lineage Analysis for PCs\n",
    "\n",
    "## Further investigate katG_p.Arg463Leu. Correlated with any lineages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fa2036a-0100-4e46-af77-23a0a5a9bac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lineages = pd.read_csv(\"data/lineages.csv\")\n",
    "lineages[[\"Lineage_1\", \"Lineage_2\"]] = lineages[\"Lineage\"].str.split(\",\", expand=True).rename(columns={0:\"Lineage_1\", 1:\"Lineage_2\"})\n",
    "del lineages[\"Lineage\"]\n",
    "\n",
    "lineages[[\"Lineage_1\", \"Count_1\"]] = lineages[\"Lineage_1\"].str.split(\"(\", expand=True)\n",
    "lineages[\"Count_1\"] = lineages[\"Count_1\"].str.strip(\")\")\n",
    "\n",
    "lineages[[\"Lineage_2\", \"Count_2\"]] = lineages[\"Lineage_2\"].str.split(\"(\", expand=True)\n",
    "lineages[\"Count_2\"] = lineages[\"Count_2\"].str.strip(\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65f50718-4247-496f-96e6-cafed4917c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineages.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82388d37-90ae-4147-8d62-f11b828d3414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Isolate</th>\n",
       "      <th>Lineage_1</th>\n",
       "      <th>Lineage_2</th>\n",
       "      <th>Count_1</th>\n",
       "      <th>Count_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11050333</td>\n",
       "      <td>2.2.1</td>\n",
       "      <td>None</td>\n",
       "      <td>1/1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SAMN21856363</td>\n",
       "      <td>2.2.1</td>\n",
       "      <td>None</td>\n",
       "      <td>1/1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SAMC246113</td>\n",
       "      <td>4.5</td>\n",
       "      <td>None</td>\n",
       "      <td>1/1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SAMEA1101763</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>1/1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SAMEA1019058</td>\n",
       "      <td>4.8</td>\n",
       "      <td>None</td>\n",
       "      <td>1/1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>SAMEA7527813</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>1/1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>26_51_G1159_1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>1/1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>SAMC246418</td>\n",
       "      <td>2.2.1</td>\n",
       "      <td>None</td>\n",
       "      <td>1/1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>03_5667</td>\n",
       "      <td>2.2.1</td>\n",
       "      <td>None</td>\n",
       "      <td>1/1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>TB038060126</td>\n",
       "      <td>4.1.1.3</td>\n",
       "      <td>None</td>\n",
       "      <td>1/1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Isolate Lineage_1 Lineage_2 Count_1 Count_2\n",
       "0        11050333     2.2.1      None     1/1    None\n",
       "1    SAMN21856363     2.2.1      None     1/1    None\n",
       "2      SAMC246113       4.5      None     1/1    None\n",
       "3    SAMEA1101763         3      None     1/1    None\n",
       "4    SAMEA1019058       4.8      None     1/1    None\n",
       "..            ...       ...       ...     ...     ...\n",
       "95   SAMEA7527813         3      None     1/1    None\n",
       "96  26_51_G1159_1         3      None     1/1    None\n",
       "97     SAMC246418     2.2.1      None     1/1    None\n",
       "98        03_5667     2.2.1      None     1/1    None\n",
       "99    TB038060126   4.1.1.3      None     1/1    None\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c28a045-2dc0-41fa-bb97-d6c2e6538bee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
